{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EPA Air Quality Analysis**  \n",
    "\n",
    "## **Introduction**  \n",
    "\n",
    "Air pollution is a growing concern, and the Air Quality Index (AQI) is a crucial metric used to assess pollution levels. The AQI ranges from 0 to 500, where higher values indicate greater pollution and potential health risks. For example, an AQI below 50 represents good air quality, while an AQI above 300 is considered hazardous.  \n",
    "\n",
    "In this project, I analyze air quality data collected by the U.S. Environmental Protection Agency (EPA) to gain insights into pollution levels across different states and counties. Python data structures such as lists, dictionaries, and sets are used to store and analyze AQI data efficiently.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Structure  \n",
    "\n",
    "#### **1. c2_epa_air_quality**  \n",
    "This dataset contains air quality index (AQI) data along with state and county identifiers. It includes the following fields:  \n",
    "\n",
    "- **state_code**: A two-digit string representing the state code.  \n",
    "- **state_name**: The full name of the state.  \n",
    "- **county_code**: A three-digit string representing the county code within the state.  \n",
    "- **county_name**: The name of the county.  \n",
    "- **aqi**: A numerical value representing the air quality index for the county.  \n",
    "- **state_code_int**: An integer representation of the state code.  \n",
    "- **county_code_int**: An integer representation of the county code.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. epa_ca_tx_pa**  \n",
    "This dataset focuses on air quality data for California, Texas, and Pennsylvania. It includes:  \n",
    "\n",
    "- **state_code**: A numerical code identifying the state.  \n",
    "- **state_name**: The full name of the state.  \n",
    "- **county_code**: A numerical code identifying the county.  \n",
    "- **county_name**: The full name of the county.  \n",
    "- **aqi**: A numerical value representing the air quality index for that county.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3. epa_others**  \n",
    "This dataset contains air quality data for states other than California, Texas, and Pennsylvania. It shares the same structure as *epa_ca_tx_pa*:\n",
    "\n",
    "- **state_code**: A numerical identifier for the state.  \n",
    "- **state_name**: The full name of the state.  \n",
    "- **county_code**: A numerical identifier for the county.  \n",
    "- **county_name**: The full name of the county.  \n",
    "- **aqi**: A numerical value representing the air quality index for that county.  \n",
    "\n",
    "All three datasets follow a consistent structure, allowing for easy merging and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importing Required Libraries**\n",
    "First, I import the necessary libraries for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, I load the dataset containing AQI records along with the state and county where each reading was recorded. My goal is to structure this data for easy retrieval and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by converting the raw data into a structured format. Specifically, I create a list of tuples where each tuple contains three key pieces of information:\n",
    "\n",
    "- State Name\n",
    "- County Name\n",
    "- AQI Value\n",
    "  \n",
    "This format ensures that each AQI reading is associated with its respective location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset  \n",
    "epa_data = pd.read_csv(r'C:\\Users\\saswa\\Documents\\GitHub\\EPA-Air-Quality-AQI-Analysis\\Data\\c2_epa_air_quality.csv')  \n",
    "\n",
    "# Convert columns to lists  \n",
    "state_list = epa_data['state_name'].to_list()  \n",
    "county_list = epa_data['county_name'].to_list()  \n",
    "aqi_list = epa_data['aqi'].to_list()  \n",
    "\n",
    "# Create list of tuples  \n",
    "epa_tuples = list(zip(state_list, county_list, aqi_list))  \n",
    "\n",
    "# Display first five records  \n",
    "epa_tuples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a Dictionary for AQI Data**\n",
    "To allow for efficient data retrieval, the tuples are converted into a dictionary where states act as keys, and the values are lists of county-level AQI records. This enables quick lookups and better organization of air quality information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_dict = {}  \n",
    "\n",
    "for state, county, aqi in epa_tuples:  \n",
    "    if state in aqi_dict:  \n",
    "        aqi_dict[state].append((county, aqi))  \n",
    "    else:  \n",
    "        aqi_dict[state] = [(county, aqi)]  \n",
    "\n",
    "# Example: Retrieve data for Vermont  \n",
    "aqi_dict['Vermont']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploring the Data**\n",
    "Now that I have a structured dataset, I can extract meaningful insights from the AQI records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Number of AQI Readings for Arizona**\n",
    "The total number of AQI readings recorded in Arizona is calculated using Python’s len() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_cnt = len(aqi_dict['Arizona'])  \n",
    "print(recordings_cnt)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mean AQI for California**\n",
    "To determine the average air quality in California, I compute the mean of all AQI values recorded in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sum and len  \n",
    "aqi_mean = sum(aqi for county, aqi in aqi_dict['California']) / len(aqi_dict['California'])  \n",
    "print(aqi_mean)  \n",
    "\n",
    "# Using statistics.mean()  \n",
    "aqi_mean1 = statistics.mean(aqi for county, aqi in aqi_dict['California'])  \n",
    "print(aqi_mean1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyzing County-Specific AQI Readings**\n",
    "A function is defined to count how many times a county appears in a given state's AQI records. This allows me to assess data distribution across different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_counter(state_name):  \n",
    "    county_dict = {}  \n",
    "    for county, aqi in aqi_dict[state_name]:  \n",
    "        if county in county_dict:  \n",
    "            county_dict[county] += 1  \n",
    "        else:  \n",
    "            county_dict[county] = 1  \n",
    "    return county_dict  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking AQI Readings for Washington County, PA**\n",
    "Using county_counter(), I determine how many AQI readings are recorded for Washington County in Pennsylvania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_dict = county_counter('Pennsylvania')  \n",
    "pa_dict['Washington']  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Listing Counties in Indiana**\n",
    "Retrieving the names of counties represented in Indiana’s AQI records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_counter(\"Indiana\").keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding Counties with Duplicate Names**\n",
    "To check how many counties share the same name across different states, I compile a list of all counties and analyze name repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a list of every county in the dataset  \n",
    "all_counties = []  \n",
    "for state_name in aqi_dict.keys():  \n",
    "    all_counties += list(county_counter(state_name).keys())  \n",
    "\n",
    "# Finding total number of counties  \n",
    "print(len(all_counties))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculating Counties with Duplicate Names**\n",
    "Using a set and list methods, I determine the number of county names that appear more than once across states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_count = 0  \n",
    "\n",
    "for county in set(all_counties):  \n",
    "    count = all_counties.count(county)  \n",
    "    if count > 1:  \n",
    "        shared_count += count  \n",
    "\n",
    "print(shared_count)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This doesn't tell us how many different county names are duplicated. Further analysis could uncover more details about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to find out how many different county names are duplicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_count = 0  \n",
    "\n",
    "for county in set(all_counties):  \n",
    "    count1 = all_counties.count(county)  \n",
    "    if count1 > 1:  \n",
    "        county_count += 1  \n",
    "\n",
    "print(county_count)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vectorized Operations: Using NumPy for Efficient Analysis**\n",
    "\n",
    "In this section, I used NumPy, a powerful library for numerical computing, to analyze AQI data. NumPy provides fast operations on large arrays, enabling efficient calculations on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Converting AQI Data into an Array**\n",
    "Using the AQI data list, I convert it into a NumPy ndarray for efficient computation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_list = epa_data['aqi'].to_list()\n",
    "aqi_array = np.array(aqi_list) \n",
    "print(len(aqi_array)) \n",
    "print(aqi_array[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deriving Summary Statistics**\n",
    "Next, I calculate some key summary statistics of the AQI data:\n",
    "\n",
    "- Maximum AQI value\n",
    "- Minimum AQI value\n",
    "- Median AQI value\n",
    "  \n",
    "Standard deviation of AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max = {np.max(aqi_array)}\")\n",
    "print(f\"Min = {np.min(aqi_array)}\")\n",
    "print(f\"Median = {np.median(aqi_array)}\")\n",
    "print(f\"Std = {np.std(aqi_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyzing Cleanest AQI Readings**\n",
    "The goal is to analyze how many readings represent the cleanest air (defined as AQI values of 5 or less). Using NumPy’s element-wise operations, I can quickly calculate the percentage of readings that fall into this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask where True represents AQI values ≤5\n",
    "boolean_aqi = (aqi_array <= 5)  \n",
    "\n",
    "# Calculate the percentage of AQI values that are 5 or less\n",
    "percent_under_6 = boolean_aqi.sum() / len(boolean_aqi)  \n",
    "print(f\"Percentage of AQI readings ≤5: {percent_under_6:.2%}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Manipulation with pandas: Exploring Air Quality Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the AQI Data into a DataFrame**\n",
    "For this analysis, I started with a dataset containing air quality data from three states: California, Texas, and Pennsylvania. The first step was to load the data into a pandas DataFrame and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "top3 = pd.read_csv(r'C:\\Users\\saswa\\Documents\\GitHub\\EPA-Air-Quality-AQI-Analysis\\Data\\epa_ca_tx_pa.csv')\n",
    "\n",
    "# Display the first five rows of the dataset\n",
    "top3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Examining Metadata and Summary Statistics**\n",
    "Once the dataset is loaded, the next step is to explore the basic information, such as the number of rows and columns, column names, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata of the dataframe\n",
    "top3.info()\n",
    "\n",
    "# Generate summary statistics for the numeric columns\n",
    "top3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploring the Data: Insights by State and AQI**\n",
    "To better understand the distribution of the data, I'll start by examining the number of observations per state and sorting the data by AQI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows per state\n",
    "top3['state_name'].value_counts()\n",
    "\n",
    "# Sort the data by AQI values in descending order\n",
    "top3_sorted = top3.sort_values('aqi', ascending=False)\n",
    "\n",
    "# Display the top 10 rows with the highest AQI values\n",
    "top3_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Investigating the California Data**\n",
    "Now, focusing on the California data, I'll use Boolean masking to filter and analyze the relevant records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Boolean mask to filter California data\n",
    "mask = top3_sorted['state_name'] == 'California'\n",
    "ca_df = top3_sorted[mask]\n",
    "\n",
    "# Display the first five rows of California data\n",
    "ca_df.head()\n",
    "\n",
    "# Verify the number of rows in the California data\n",
    "ca_df.shape\n",
    "\n",
    "# Count occurrences of each county in California\n",
    "ca_df['county_name'].value_counts()\n",
    "\n",
    "# Calculate the mean AQI for Los Angeles county\n",
    "mean_aqi = ca_df[ca_df['county_name'] == 'Los Angeles']['aqi'].mean()\n",
    "print(mean_aqi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grouping Data by State**\n",
    "To calculate the average AQI per state, I can group the data by the state_name and apply aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by state and calculate the mean AQI\n",
    "top3.groupby('state_name').agg({'aqi': 'mean'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding Data from Other States**\n",
    "To expand the dataset, the next step is to load data from another file containing information for the remaining states, and then combine it with the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second dataset\n",
    "other_states = pd.read_csv(r'C:\\Users\\saswa\\Documents\\GitHub\\EPA-Air-Quality-AQI-Analysis\\Data\\epa_others.csv')\n",
    "\n",
    "# Display the first five rows of the new dataset\n",
    "other_states.head(5)\n",
    "\n",
    "# Concatenate the data from top3 and other_states into a new dataframe\n",
    "combined_df = pd.concat([top3, other_states])\n",
    "\n",
    "# Verify the length of the combined dataframe\n",
    "len(combined_df) == len(top3) + len(other_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtering Washington Data with Moderate AQI**\n",
    "In this section, I'll apply complex Boolean masking to filter data from Washington where AQI values are considered \"Moderate\" (betIen 51 and 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Boolean mask to filter Washington data with Moderate AQI\n",
    "wa_df = combined_df[(combined_df['state_name'] == 'Washington') & (combined_df['aqi'] >= 51)]\n",
    "\n",
    "wa_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**\n",
    "By leveraging the power of NumPy and pandas, this project successfully analyzed and summarized a large dataset of AQI readings across various U.S. states. Through careful data manipulation, statistical analysis, and efficient use of vectorized operations, I was able to extract meaningful insights that could inform environmental decision-making. Using dictionaries and sets alloId for quick organization and analysis of data by state and county, while NumPy provided the tools for performing complex statistical calculations efficiently.\n",
    "\n",
    "This analysis demonstrated the effectiveness of structured data manipulation using Python. By combining dictionary-based storage with NumPy’s computational efficiency and pandas’ data handling capabilities, key insights into AQI trends across U.S. states Ire extracted. This process is vital for making timely, data-driven decisions to improve environmental policies and protect public health. Pandas, with its intuitive methods for data handling, played a crucial role in simplifying complex data analysis tasks and enhancing decision-making efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Top Three Recommendations**\n",
    "- Focus on High AQI Areas: By identifying regions with consistently high AQI values, particularly in states like California, targeted interventions could be introduced, such as air quality improvement initiatives and health advisories.\n",
    "- Enhance Data Reporting: Regularly update and expand the AQI dataset to include more regions and time periods, which would offer better insights into long-term trends and the effectiveness of air quality policies.\n",
    "- Promote Public Awareness Campaigns: Using the insights from AQI data, create targeted awareness campaigns in high-pollution areas, focusing on the health risks associated with poor air quality and encouraging actions to reduce emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Application of Insights**\n",
    "The insights gained from the AQI data can be directly applied to public health and environmental policy. By identifying regions with high pollution levels, policymakers can prioritize those areas for interventions such as stricter emission controls, improved urban planning, or better pollution monitoring. Additionally, this analysis can inform public health campaigns aimed at educating communities on the risks of high AQI levels and encouraging proactive measures to reduce exposure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Next Steps**\n",
    "- Further Data Expansion: To deepen the analysis, consider incorporating AQI data from more regions and additional environmental factors such as temperature or traffic density, which could affect air quality.\n",
    "- Collaborate with Environmental Agencies: Share the findings with local environmental protection agencies to help guide more effective air quality control policies and interventions.\n",
    "- Develop Predictive Models: Explore the possibility of building predictive models that forecast AQI levels based on various factors (e.g., Iather, traffic, industrial activity), helping authorities take preventative actions in advance.\n",
    "\n",
    "These steps provide a clear path forward for further utilizing data to make impactful decisions regarding air quality management and public health."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
